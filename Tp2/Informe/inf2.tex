\documentclass[spanish,12pt]{article}
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{xspace}
\usepackage{lmodern}
\usepackage{indentfirst}
\usepackage{xargs}
\usepackage{ifthen}
\usepackage{fancyhdr}
\usepackage{latexsym}
\usepackage{lastpage}
\usepackage{textcomp}
\usepackage{varwidth}
\usepackage{caratula, aed2-tad,aed2-symb,aed2-itef}
\usepackage{algorithmicx, algpseudocode, algorithm}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\usepackage{anysize}
\marginsize{1.5cm}{1.5cm}{1.5cm}{1.5cm}

\begin{document}

\titulo{Informe 2}
\materia{Algoritmos y Estructuras de Datos III}
\author{Grupo  \\Alvarez Vico Jazm\'in\\Cortés Conde Titó Javier María\\Pedraza Marcelo \\ Rozenberg Uriel Jonathan}

\integrante {Jazmín Alvazer Vico}{75/15}{jazminalvarezvico@gmail.com}
\integrante {Marcelo Pedraza}{393/14}{marcelopedraza314@gmail.com}
\integrante {Uriel Jonathan Rozenberg}{838/12}{rozenberguriel@gmail.com}
\integrante {Javier María Cortés Conde Titó}{252/15}{javiercortescondetito@gmail.com}

\maketitle


\clearpage

\tableofcontents
\cleardoublepage

\section{Problema 1: Laberinto}

\subsection{Introducción}

En este problema los viajeros encuentran un mapa de un laberinto señalando algún lugar con una x, sin embargo no todos los puntos están conectados. Ellos quisieran llegar a ese lugar caminando lo menos posible. Además, pueden esforzarse para romper una cantidad determinada de paredes. Nos piden que, de ser posible, encontremos la manera que caminen lo mínimo posible
\\
\\
Formalmente podemos modelar el problema utilzando un grafo que contiene nodos ``especiales"(las paredes). Se busca la distancia entre dos nodos, pasando como mucho por p nodos especiales.

\subsection{Explicación de la solución}
Podemos dividir la resolución en tres partes: la primera, donde interpretamos la entrada y generamos un primer grafo, en el cual las habitaciones y paredes son nodos, y dos nodos son adyacentes si y sólo si sus casillas originales lo son. En la segunda parte copiaremos el primer grafo tantas veces como paredes se puedan romper, de manera que la acción de romper una pared esta representada por un cambio de nivel en el grafo. Así, cada nivel muestra cuántas paredes fueron atravesadas, y los $p+1$ nodos finales, los finales con p paredes atravesadas.


\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{pto1}
\caption{imagen explicativa}
\end{figure}



En la tercera parte, vamos a aplicar un bfs modificado para calcular las distancias del nodo origen a todos los demás nodos. Entre las modificaciones se incluyen unos $``$movimientos ilegales$"$ . Por un lado, no está permitido pasar a un nivel menor al que uno se encuentra. Además, no es correcto mover de un nodo $``$habitación$"$ a un nodo $``$pared$"$ en el mismo nivel. Estas son acciones que en nuestro modelo no tienen correlación con ninguna situación del problema, y que podrían generar camínos mínimos incorrectos. 
\\
\\
Por último, se calcula la distancia mínima entre todos los nodos finales copiados. Si no existe un camino posible a ninguno de los nodos finales en todos los niveles, el algoritmo devuelve -1



\subsection{Pseudocódico}

\subsubsection{Pseudocódigo}

\begin{algorithm}[H]{\textbf{solucion}(vector$<$Nodo$>$nodos, vector$<$Eje$>$ ejes, int p)}
	\begin{algorithmic}[1]
		
		\State \quad vector$<$Nodos$>$ aux$\gets$nodos
		\State \quad  Desde $i=0$ hasta $i=p$
			\State \quad \quad aux$\gets$ ClonarUltimoNivel(aux,ejes)
		\State \quad finDesde
		\State \quad res$\gets$ Bfs(aux)
		\State \quad devolver res
	\end{algorithmic}
\end{algorithm}

Este algoritmo llama a ClonarUltimoNivel la cantidad de paredes que se tiene permitido romper, y luego hace un bfs sobre el nuevo grafo.


\begin{algorithm}[H]{\textbf{Bfs}(vector$<$Nodos$>$ nodos)}
	\begin{algorithmic}[1]
		\State \quad Para todo nodo i
			\State \quad \quad  pred(i)$\gets$ $-1$, order(i)$\gets$ $-1$
		\State \quad finPara
		\State \quad final $\gets$ $-1$
		\State \quad next$\gets$ 0
		\State \quad list$\gets${(0,0)}
		\State \quad Mientras list $\neq \emptyset$ hacer
			\State \quad \quad Sacar un elemento (i,padre)
			\State \quad \quad pred(i,padre)=padre
			\State \quad \quad Si order(i=-1) hacer
				\State \quad \quad \quad order(i)$\gets$next
				\State \quad \quad \quad incrementar next
				\State \quad \quad \quad Si i es un nodo final
					\State \quad \quad \quad \quad final $\gets$i
					\State \quad \quad \quad \quad cortar el mientras
				\State \quad \quad \quad Para cada nodo j vecino al nodo i hacer:
					\State \quad \quad \quad \quad Si(order(j)$=-1$ y nivel(j) $\geq$ nivel(i) y (nivel(j)$\neq$nivel(i) o j no es pared )  ) hacer
						 \State \quad \quad \quad \quad \quad list$\cup${(j,i)}
					\State \quad \quad \quad \quad finSi
				\State \quad \quad \quad   finPara
			\State \quad \quad  finSi
		\State \quad finMientras
		\State \quad res$\gets$2
		\State \quad aux$\gets$0
		\State \quad Si final $= -1$
		\State \quad \quad devolver $-1$
		\State \quad finSi		
		\State \quad Mientras  final $\neq 0 \ y \ $final $\neq -1 $ hacer
			\State \quad \quad  final$\gets$pred(final)
			\State \quad \quad incrementar res
			\State \quad \quad incrementar aux
		\State \quad finMientras
		\State \quad devolver res


	\end{algorithmic}
\end{algorithm}
Este algoritmo aplica un bfs: por cada nodo visitado, mira a todos sus vecinos  

\begin{algorithm}[H]{\textbf{ClonarUltimoNivel}(aux,ejes)}
	\begin{algorithmic}[1]
		\State \quad n $\gets$último nodo  de aux
		\State \quad nivel $\gets$ el nivel del n
		\State \quad tamanioDelUltimoNivel $\gets$ 0 
		\State \quad mientras exista n y el nivel de n = nivel
			\State \quad \quad retrocedo un nodo
			\State \quad \quad incremento tamanioDelUltimoNivel
		\State \quad finMientras
		\State \quad Para i desde 0 hasta tamanioDelUltimoNivel
		  	\State \quad \quad nuevoNodo $\gets$copia de n
			\State \quad \quad indice del nuevoNodo$\gets$ indice de n + tamanioDelUltimoNivel
			\State \quad \quad agrego nuevoNodo al final de aux
		\State \quad Fin Para
		\State \quad Para e en ejes
		 	\State \quad \quad Si e tiene ambos ejes incidentes a nodos en el ultimonivel
		 		\State \quad \quad \quad nuevoEje$\gets$copia del eje, pero incidente a los nodos del nuevo nivel
		  		\State \quad \quad \quad  Agrego nuevoEje al final de ejes
		 	\State \quad \quad fin Si
		\State \quad Fin Para
		\State \quad para n en nodos
		  	\State \quad \quad  Si n es pared
				\State \quad \quad \quad Para e en los ejes de n
					\State \quad \quad \quad \quad  nuevoEje$\gets$copia del otro eje que conecta n con su clon del nuevo nivel
					\State \quad \quad \quad \quad Agrego nuevoEje al final de ejes
				\State \quad \quad \quad Fin Para
			\State \quad \quad Fin Si
		\State \quad Fin Para
	\end{algorithmic}
\end{algorithm}
%%%%%%%%%% Agregué todas las tabulaciones que faltaban. Espero que esten en el lugar correcto :3
%%%%%%%%%% cambie <- por /gets. Lo puse mas en palabras



\subsection{Demostración de Correctitud}
Para demostrar que este algoritmo devuelve lo pedido, podemos ver que todos los movimientos en el tablero estan representados por la posibilidad(o no) de visitar a un vecino. De esta manera, todos los caminos posibles(y sólo esos) están considerados a la hora de hacer bfs.\\
Movimientos legales:\\
\\
Moverse de una habitación a otra; corresponde a 2 nodos $``$habitación$"$ adyacentes. Como en todos los niveles creados esta adyacencia se mantiene, este movimiento siempre es posible.\\
\\
Romper una pared; corresponde a un $``$cambio de nivel$"$. Pasas de un nodo $``$habitación$"$ de nivel i a un nodo $``$pared$"$ de nivel i+1. Como existen P niveles, se pueden observar todos los caminos distintos, rompiendo las paredes en distintas situaciones. Notar que el algoritmo explícitamente prohíbe estos movimientos en el mismo nivel, para evitar falsos resultados.\\
\\
Moverse de una pared a otro lado; este caso está siempre conectado en un mismo nivel, y con una guarda en el bfs para evitar la vuelta.

\subsection{Demostración de Complejidad}
Para poder probar que este algoritmo cumple la complejidad pedida, vamos a demostrar que en el grafo final(luego de la clonación) los ejes son, como mucho, ocho veces la cantidad de nodos.
Podemos ver que, por un lado, en el grafo sin clonar, cada nodo puede tener dos(si está en una de las cuatro esquinas del tablero) tres(en los bordes) o cuatro(en el medio) ejes. Además, a la hora de clonar, creas un nuevo eje si y sólo si los adyacentes son distintos. Es decir, una habitación y una pared. De esta manera, el caso máximo de vecinos que puede tener un nodo es si todos sus vecinos son del otro tipo, tanto si es una habitación rodeada de paredes, o una pared rodeada de habitaciones.
%Si recuperamos este ejercicio(je) estaria bueno poner una representacion de esto.

Una vez pasado por eso, vemos que todos los ciclos de $ClonarUltimoNivel$ tienen complejidad $O(n)$, con n siendo los nodos. Como todos los elementos de la matriz menos los bordes son nodos, es lo mismo decir que la complejidad es $\mathcal{O}$(F*C). En la solución, por un lado se aplica $ClonarUltimoNivel$ p veces (dando una complejidad de $\mathcal{O}$(F*C*P) ), y luego se aplica bfs sobre el grafo clonado. El grafo clonado tiene $n*p$ nodos, con una cantidad de ejes acotado por lo mencionado anteriormente, llegando a una complejidad de $\mathcal{O}$(F*C*P). En conclusión, el algoritmo propuesto tiene una complejidad de $\mathcal{O}$(F*C*P), cumpliendo con la cota pedida.
\subsection{Experimentación, resultado y análisis }
Para el análisis de este algortimo lo que hicimos fue separar las mediciones en dos casos, teniendo fc y p variable.Esto significa que tomamos laberintos cuyo tamaño estaba fijo y fuimos midiendo el algoritmo
aumentando el valor de P paulativamente.



\begin{figure}[H]
\centering
\includegraphics     [width=0.6\textwidth]{fcfijo}
\caption{}
\end{figure}

Se aprecia en este gráfico que si solo varía P, obtenemos un comportamiento lineal respecto a FC, dado que el cambio es la clonación de un nivel.


\begin{figure}[H]
\centering
\includegraphics     [width=0.6\textwidth]{pfijo}
\caption{}
\end{figure}
En este gráfico se ve que si sólo varía FC también obtenemos un comportamiento lineal respecto a P.
Con esto queremos mostrar como se puede apreciar que el algoritmo tiene un comportamiento de F*C*P. Podríamos haber variado respecto a F o C respecto a las otras dos variables pero dada nuestra representación
por cada caracter del laberinto tenemos un nodo, siendo equivalente a variar directamente los nodos, es decir, variar F y C juntas.


\\
\\
\\
\\



Por último, teníamos la intuición de que si agregábamos más paredes, el proceso de clonación iba a ser ``más pesado" y por ende aumentar la complejidad, así que decidimos mantener constante F C Y P e ir solamente agregándo al laberinto más paredes
\begin{figure}[H]
\centering
\includegraphics     [width=0.6\textwidth]{paredesfijas}
\caption{}
\end{figure}

%ESTO ES BASURA
Este experimento nos dejó medio confundidos ya qye aparentemente tiene un comportamiento más cercano a decreciente. Y lo más cercanos que estamos a tener una deduccion posible de lo que estuvo ocurriendo  usando el ddd para ver cuando se realocaba memoria,
Estuvimos reusando estructuras en cada iteracion, y se iba agraandando y agrandando en cada clonacion,  resulta ser que mas alla de que usemos vectores mas pequeños en una nueva iteracion, o de un tamanio similar, el compilador ya reservó mas meoria y entonces no tuvo la necesidad de mover la estructura a una neuva posicion con mas espacio.
%ESTO SIGUE SIENDO BASURA


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problema 2: Juntando piezas }

\subsection{Introducción}

En este problema nuestros arqueólogos quieren recorrer todas las salas, para ello pueden romper las paredes. Sin embargo, romperlas no cuesta el mismo esfuerzo para todas. Teniendo un mapa con los esfuerzos cuantificados del 1 al 9 desean saber cuál es el mínimo esfuerzo que deben hacer para cumplir su objetivo.

Formalmente, podemos modelar este problema con grafos. Teniendo un grafo con peso se desea encontrar el árbol generador mínimo y devolver la sumatoria del peso de todos sus ejes.

\subsection{Explicación de la solución}

Nuestra entrada es un ``mapa" que contiene `` . ", $``\# "$ y números, es decir una matriz que en cada posición tiene alguno de esos simbolos. los puntos representan lugares caminables. Cada punto lo representamos con un nodo. los números son las paredes que se pueden romper y los numerales son las paredes irrompibles. Los nodos pueden conectarse a otros nodos que estén vertical o horizontalmente al mismo sí son continuos o tienen una pared rompible en el medio.

Definimos una clase eje que tiene como propiedad punteros a los nodos de cada extremo y un peso que representa cuanto cuesta romper la pared que existe entre ellos. Si dos salas son continuas, es decir no tienen un número o numeral en el medio el eje que las une tendrá peso cero. Sí entre dos nodos hay un número, ese será el peso del eje que los une. De haber un numeral, como esa pared es irrompible, no habrá un eje que una a esos nodos.

\\
Ahora, teniendo el conjunto de todos los ejes y utilizamos el algoritmo de Kruskal para obtener el árbol generador mínimo, y retornar el valor total del mismo. 
\\
Para implementar Kruskal, utilizamos la implementación de dsu vista en clase. De esta forma agregamos dos modificaciones:
guardamos un entero en el cual ir sumando el peso de cada arista elegida para devolver como resultado y utilizamos las funciones de DSU para poder identificar cuando no hay resultado y devolver -1. Presentaremos ese fragmento del algoritmo en el pseudocodigo ya que lo consideramos relevante.

\subsubsection{Pseudocódigo}

\begin{algorithm}[H]{\textbf{solucion}(int n, vecor$<$ejes$>$ arist)}
	\begin{algorithmic}[1]
		\State \quad ColaDePrioidad$<$ejes$>$ aristas \Comment $\mathcal{O}(1)$
		\State \quad Mientras aristas $!= \emptyset $ \Comment $\mathcal{O}(m)$
		\State \qquad Tomar cada eje de arist e insertarlo en aristas \Comment $\mathcal{O}(log(m))$ esta es la complejidad que toma en c++ el ordenamiento.
		\State \quad finMientras
		\State \quad int res= Kruskal(aristas,n)  \Comment $\mathcal{O}(mlog(n) + n)$
		\State \quad devolver res \Comment $\mathcal{O}(1)$

	\medskip
        \Statex \underline{Complejidad:} $\matchal{O}(mlog(m)) + \matchal{O}(mlog(n)+n) = \matchal{O}(m(log(m)+log(n))+n)$
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]{\textbf{Fragmento Kruskal}()}
	\begin{algorithmic}[1]
		\State \quad j $\gets$ 1, b $\gets$ true, res$\gets$1, nod $\gets$ el padre del nodo 1
		\State \quad Mientras j$<$n y b \comment   $\mathcal{O}(n)$
		\State \qquad Si el padre del nodo j es distinto a nod  \Comment $\mathcal{O}(1)$
		\State \qquad \quad b $\gets$ false  \Comment $\mathcal{O}(1)$
		\State \qquad \quad res $\gets$ -1 \Comment $\mathcal{O}(1)$
		\State \qquad finSi
		\State \qquad j $\gets$ j+1 \Comment $\mathcal{O}(1)$
		\State \quad finMientras 
		\State \quad devovler res; \Comment $\mathcal{O}(1)$
		
	\medskip
        \Statex \underline{Complejidad:} $\matchal{O}(n)$ esto le aporta el $``+n "$ a la complejidad del Kruskal 
	\end{algorithmic}
\end{algorithm}

\subsubsection{Demostración de Correctitud}

Este problema lo modelamos con grafos de modo tal que cada habitación caminable es un nodo conectado a otros mediante sus ejes. Los mismos, de haber una pared en el medio tendrán peso igual al costo de destruirla y, de no haber pared, tendrán peso cero. Si entre dos nodos hay una pared indestructible esos nodos no podrán conectarse, es decir no existe una arista entre ellos.
\\
Un arbol generador mínimo de un grafo es un subgrafo que contiene todos los nodos del mismo y es un árbol  que cumple que la sumatoria de los pesos de sus ejes es la menor posible. Es decir, no existe otro arbol generador tal que la sumatoria del peso de sus ejes sea mayor que la del AGM.
También podemos garantizar que es mejor que cualquier subgrafo no arbol, ya que implicaría que tiene circuitos, y esto siempre agregaría peso de más ya que habría aristas de más.
\\
En este problema nos piden que demos el esfuerzo minimo que nos cuesta acceder a todas las habitaciones. Por como modelamos el problema y las definiciones previas, esto es equivalente a encontrar el conjunto de aristas que conectan todos los nodos tal que minimzen la sumatoria de sus pesos.
Como los ejes que conectan nuestros nodos continuos tienen peso cero, entonces no gregan peso a nuestro resultado. Es decir, que el resultado será el mismo que si las consideraramos como una sola sala.  
 Entonces podemos ver que lo que nos están pidiendo es un AGM. Si el problema tiene solución, para encontrar el AGM del grafo utilizamos el algoritmo Kruskal. La demostración de correctitud de este algoritmo puede encontrase en el paper de  J.B. Kruskal, ``On the shortest spanning subtree of a graph and the traveling salesman problem. Proceedings of the American Mathematical Society, Volume 7, pp. 48-50, 1956".
\\
En caso de que el problema no tenga solución utilizamos las funciones de dsu para devolver -1. Basicamente, si no existe un AGM posible es porque el grafo no es conexo. En este caso exisitrán un par de nodos que al finalizar el kruskal no tendrán el mismo nodo padre. 


\subsubsection{Demostración de Complejidad}


Como podemos apreciar en el pseudocódigo nuestro algoritmo tiene complejidad $\mathcal{O}(m(log(m)+log(n))+n)$ donde m es la cantidad de ejes y n la cantidad de nodos de nuestro grafo.
La complejidad pedida para este algoritmo es $\mathcal{O}(FClog(FC))$ donde F es la cantidad de filas y C la cantidad de columnas del mapa.

\\
Primero probaremos que podemos acotar la cantidad de ejes por la cantidad de nodos:
\\
Sabemos que
\\
 $1/2  \sum_{1}^{n}d(v_{i}) =m $. 
\\
Sin embargo podemos acotar $d(v_{i}) \leq 4$ ya que como mucho los nodos del medio del mapa pueden tener 4 ejes mientras que todos los que estén en los bordes podrán tener como mucho 2.
\\
 Luego $1/2  \sum_{1}^{n}{d(v_{i})} \leq 1/2 \sum_{1}^{n}{4} = 2n$.
\\
 Entonces $m \leq 2n$ y $\mathcal{O}(m) \leq \mathcal{O}(2n) \mathcal{O}(n)$.
\\
Ahora veremos que la complejidad de nuestro algoritmo es la pedida:
\\
Por lo anterior tenemos que $\mathcal{O}(m(log(m)+log(n))+n)= \mathcal{O}(n(2log(n)+1)) = \mathcal{O}(nlog(n))$.
\\
La cantidad de nodos que tengamos depende directamente de F y C. la máxima cantidad de nodos que podemos tener es F-1*C-1 (la matriz sin paredes descartando los bordes) 
\\
Luego $\mathcal{O}(nlog(n)) = \mathcal{O}(FClog(FC))$


\subsection{Experimentación}

La complejidad requerida para este algoritmo es $\mathcal{O}(FClog(FC))$ y en la sección anterior probamos que esto es equivalente a  $\mathcal{O}(nlog(n))$.
Realizamos una serie de experimentos para respaldar empíricamente este hecho.

Los mismos consisten principalmente en variar las dimensiones del mapa, es decir, modificar F y C. Esperamos que estas variaciones afecten la cantidad de nodos, aumentando o disminuyendo la complejidad a corde de $\mathcal{O}(FClog(FC))$ manteniendo la misma tendencia.

Creemos que nuestro algoritmo será un poco más rápido a la cota pedida ya que la cantidad de nodos es un poco menor a FC.

Nuestro algoritmo devuelve -1 cuando se tiene más de una componenete conexa, es decir cuando no se pueden recorrer todas las salas. Decimdimos hacer un test para ver que ocurría en estos casos. al disminuir las componentes conexas tambien disminuimos la cantidad de nodos, por esta razón suponemos que debe tardar menos. si no las disminuyeramos creemos que el tiempo sería el mismo.
\\
Cada instancia de los experimentos fue iteradada 3000 veces, y se calculó el promedio.

\subsubsection{Resultados y análisis}

En nuestro primer experimento fuimos aumentando la dimensión de nuestro mapa, con F=C. lo corrimos para F=10 hasta F=250 aumentando de diez en diez.

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{sinParedes}
\caption{Aumento en la dimensión sel grafo}
\end{figure}


Podemos observar que el algoritmo tiene la misma tendencia logarítmica que nuestra cota teórica. También podemos ver que es mejor a medida que aumenta la cantidad de nodos (o filas y columnas).
\\
\\

En este experimento mantuvimos, o bien constante el número de filas, para aumentar de 10 en 10 las columnas hasta 250, o bien el número de columnas para aumentar las filas. 

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{soloFilas}
        \caption{Aumento en filas del mapa.}
        \label{}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{soloColumnas}
        \caption{Aumento en columnas del mapa.}
        \label{}
    \end{subfigure}
\end{figure}

Podemos ver que estos gráficos son practicamente iguales. con esto podemos mostrar que el algoritmo no depende en realidad de la cantidad de filas o columnas sino de los nodos. La razón por la cual nuestros gáficos son iguales es que mantienen la misma cantidad de nodos. la única diferencia en nustros mapas sería que uno es vertical y otro horizontal pero eso no afecta la cantidad de nodos.
\\
\\

Para este experimento creamos dos matrices manteniendo en una constante C=4 (habiendo entonces dos columnas de nodos) y en la otra C=6(habiendo 4 columnas de nodos). Fuimos aumentando las filas según como correspondiera en cada caso para mantener siempre la misma cantidad de nodos en ambos grafos.
\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{2columvs4colum}
\caption{misma cantidad de nodos en mapas con distinta distribución}
\end{figure}

Podemos ver que el caso de 4 columnas tiene un tiempo de ejecución mayor. Esto se debe a que el algoritmo Kruskal tiene complejidad $\mathcal{O}(mlog(n))$ y aunque en nuestro algoritmo podamos acotar la cantidad de ejes por la cantidad de nodos, esta diferencia sigue siendo perceptible como podemos observar en la figura. El grafo con 4 columnas tiene más ejes que el grafo con 2 puesto que los nodos del medio contienen cuatro ejes mientras que en el de 2 columnas la máxima cantidad de ejes que se puede aspirar a tener es 3 en los nodos que no son vértices.
\\
\\

En este experimentos tomamos un mapa con F=C=31 y fuimos aumentando las componentes  conexas, agregando alternadamente una columna de $``\#"$ en el mapa.
\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{CompConexas}
\caption{Aumento de las componentes conexas del grafo}
\end{figure}

Como podemos observar en esta figura el tiempo de ejecución disminuye a medida que aumentan las componentes conexas. Creemos que esto se debe principalmente a la disminusión de la cantidad de nodos.






\section{Problema 3: Escapando}

\subsection{Introducción}

En este problema, los exploradores se encuentran en un dilema, luego de romper varias paredes la fortaleza se esta derrumbando. Por suerte ellos se encuentran en una habitación que tiene varios carritos y un mapa que les indica que estaciones estan conectadas y cuanto tardan en llegar de estación a estación. Lo que quieren es la forma más rápida de llegar desde el lugar en donde estan hasta la salida, que sería la última estación.

Formalmente, tenemos un digrafo rotulado, con peso en los ejes, y cada nodo esta identificado por un número desde el uno hasta la cantidad de nodos. Nuestro objetivo es encontrar el camino mínimo, devolviendo el tiempo y su conjunto de nodos.


\subsection{Explicación de la solución}

   En esta sección explicaremos por que el problema dado se puede adapatar al algoritmo de camino mínimo de Dijkstra.
 La precondición que el algoritmo pide es que no tenga ejes negativos. Como el peso de los ejes esta definido como el tiempo que se tarda de llegar del nodo de origen al nodo de llegada podemos asegurarnos que nunca vamos a tener una entrada, que nos importe, que tenga un eje con peso negativo.

\subsubsection{Pseudocódigo}

\begin{algorithm}[H]{\textbf{Solución}(input: Arreglo[(Origen, Destino, Tiempo)])}
	\begin{algorithmic}[1]
		\State LecturaDatos(input, matAdy) $\comment$ Parte 1
		\State valor $\gets$ CaminoMinimo(matAdy, estaciones) $\comment$ Parte 2 y Parte 3
		\State res $\gets$ valor $\land$ estaciones
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]{\textbf{LecturaDatos}(input: Arreglo[(Origen, Destino, Tiempo)], matAdy: Matriz(TiempoM, OrigenM))}
	\begin{algorithmic}[1]
		\State Origen, Destino, Tiempo, TiempoM y OrigenM son Nat, simplifica la lectura
		\State Incializa matAdy con (-1, -1);
		\State $\forall$ x $\in$ input
		\State \quad aux $\gets$(Tiempo(x), Origen(x))
		\State \quad tiempoaux $\gets$ TiempoM(matAdy[Origen(x)][Destino(x)])
\\
		\qquad \textbf{if} tiempoaux $\neq$ -1 $\vee$ tiempoaux $\geq$ Tiempo(x)
			\State \qquad \quad matAdy[Origen(x)][Destino(x)] $\gets$ Tiempo(x)
\\
		 \qquad \textbf{endif}
	\end{algorithmic}
\end{algorithm}

	Como no se sabe mucho de que input acepta el algoritmo, es decir, puede perfectamente un digrafo decidimos que era importante aclarar con el pseudocodigo de la lectura de datos como creamos la matriz de adyacencia. Como es un digrafo la convencion que tomaremos es que dada una posición M$_{ij}$ i es el origen y j es el destino. Luego en vez de solo representar el peso del eje tambien tenemos martcado cual es el predecesor, se inicializa los valores con valores que nunca vamos a tomar para saber si ese eje pertenece al grafo o no.

\begin{algorithm}[H]{\textbf{CaminoMinimo}(MatrizAdy: Matriz(Nat, Nat) , estaciones: vector$<$Nat$>$)}
	\begin{algorithmic}[1]

		\State n $\gets$ tamaño(MatrizAdy) $\comment$ Comienzo de Parte 2
		\State NodosSeguros $\gets$ 1
		\State nodosNoSeguros $\comment$ conjunto $\{$2, ..., n$\}$
		\State mientras NodosSeguros $\neq$ G
		\State \quad nodomin $\gets$ buscarMin(nodos, MatAdy[1])
		\State \quad nodosNoSeguros - $\{$nodomin$\}$
		\State \quad NodosSeguros $\cup$ $\{$nodomin$\}$
		\State \quad \forall \ e \ $\in$ nodosNoSeguros $\land$ [nodomin, e] $\in$ X
		\State \qquad longi $\gets$ $\pi_{1}$(matAdy[1][e])
		\State \qquad longmin $\gets$ $\pi_{1}$(matAdy[1][nodomin])
		\State \qquad longimin $\gets$ $\pi_{1}$(matAdy[nodomin][pos])
\\
		\qquad \textbf{if} longi $\geq$ longmin +longimin
			\State \qquad \quad matAdy[1][e] $\gets$ (longpmin + longimin, nodomin)
\\
 \qquad \textbf{endif}

		\State tiempo $\gets$ $\pi_{1}$(MatAdy[1][n]) $\comment$ Fin de Parte 2 Comienzo de Parte 3
		\State pred $\gets$ n
		\State mientras pred $\neq$ 1 \ $\land$ \ pred $\neq$ 0 (cuando no existe camino)
		\State \quad estaciones $\cup$ $\{$pred$\}$
		\State \quad pred $\gets$ $\pi_{2}$(matAdy[1][pred])

		\State res $\gets$ tiempo
 	\end{algorithmic}
\end{algorithm}

	CaminoMinimo en la parte 2 es dijkstra y en la parte 3 es recorrer la matriz para saber cuales son las estaciones que recorre el camino mínimo.





\newpage

\subsubsection{Demostración de Correctitud}
Como podemos apreciar el pseudocódigo es el algoritmo Dijsktra, entonces su correctitud se desprende de la demostración de correctitud de dijkstra que se puede encontrar en varios libros de algoritmos, en nuestro caso vamos a referenciar al libro titulado ``Introduction to Algorithms, Second Edition"  de Thomas H Cormen, Charles E. Leiserson, entre otros. La demostracion se encuentra en el capítulo 24, subsección 3 bajo el título ``Theorem 24.6: (Correctness of Dijkstra's algorithm)".

\subsubsection{Demostración de Complejidad}

%No pude tabular, ni con \quad ni con \tab ni con $\>$ ni con $\-$ pero parece ser un problema de el salto de linea.
Si analizamos con atención el pseudocódigo, tenemos tres secciones que se pueden analizar por separado y sumando sus complejidades obtendremos la complejidad total del algoritmo. La primer parte y la segunda parte combinadas son Dijkstra, la primera es la creación de la matriz y la segunda son los cálculos, la tercera parte es poner la información del camino mínimo. En los próximos párrafos nos vamos a referir a la cantidad de nodos en el gráfico como N.

\\
\begin{description}
\item[Parte 1] La primera parte a analizar es la creación de la matriz, al ser una matriz de adyacencia, la cantidad de filas es N y la cantidad de columnas es N, actualizar todos los valores es recorrer toda la matriz haciendo que la complejidad sea $\Theta$(N²)
\\
\item[Parte 2] En esta sección se encuentran dos ciclos anidados, podemos observar que el ciclo exterior hace N iteraciones ya que termina cuando el conjunto de nodos del grafo tiene el mismo cardinal que el conjunto de ``nodosSeguros'' y este último aumenta en uno por cada iteración. Dentro del ciclo principal tenemos dos operaciones que debemos tener en cuenta; sacar el nodo de la lista de ``nodosNoSeguros'' y el ciclo interno. Sacar un nodo de la lista nos va a costar encontrar el nodo y luego eliminarlo. Por la estructura que utlizamos eliminarlo no nos aporta complejidad, pero encontrar el nodo es una búsqueda lineal, es decir $\mathcal{O}$(N). La última parte que nos falta analizar para poder determinar la complejidad de los ciclos anidados es el ciclo interno. Cada iteración recorre N posiciones de la matriz, aquellas que podrían ser un eje válido, aunque hace distintas cosas dependiendo de si es un eje válido o no, el interior del ciclo aporta una complejidad constante. Reuniendo toda la información, el interior del ciclo externo nos aporta una complejidad $\mathcal{O}$(N) e itera N veces, es decir que la complejidad de la segunda parte es $\mathcal{O}$(N²).
\\
\item[Parte 3] Nos encontramos un ciclo que lee los datos de la matriz y guarda en un conjunto los nodos que tenemos que atravezar para tener el camino mínimo. La cantidad máxima de iteraciones que hace este ciclo es N, el razonamiento detrás de esta afirmación es que los ejes no tienen pesos negativos, si existe un camino mínimo, este no va a tener ciclos ya que pasar por un ciclo solo aumentaría el peso total del camino, y un camino sin ciclos en un grafo con n nodos tiene a lo sumo n-1 ejes, ya que el camino puede llegar a pasar por todos los nodos. Podemos concluir que el ciclo hace n iteraciones en el peor caso, es decir que la tercer parte es $\mathcal{O}$(N)
\\
\end{description}
\tab Ahora que analizamos las tres partes que podían llegar a dar complejidad al algoritmo sabemos que la complejidad algoritmica de la primer parte, la segunda parte y la tercera respectivamente son $\Theta$(N²), $\mathcal{O}$(N²), $\mathcal{O}$(N). Entonces como todas las complejidades pertenecen al orden de $\mathcal{O}$(N²) y esta clase de complejidad es la mìnima a la que todas pertenecen a la vez, la complejidad total es $\mathcal{O}$(N²) .

\subsection{Experimentación}

La cota de complejidad de nuestro algoritmo es $\mathcal{O}$(N²). Es decir que depende de la cantidad de nodos en un grafo.
En esta sección trataremos de respaldar esta cota mediante el análisis de los datos empíricos que obtuvimos a través del testeo de nuestros algoritmos.
\\
Tenemos dos algoritmos, los dos una variación del mismo pseudocódigo, el algoritmo sin modificaciones, A1, que busca el camino mínimo con todos los nodos y el algoritmo, A2, que se interrumpe cuando encuentra el camino mínimo que estamos buscando.
\\
 Decidimos testear sobre los dos algoritmos ya que al asignar peso aleatorio a los ejes en la mayoría de los casos teníamos la intuición de que los gráficos podrían quedar bastante mal. Pensamos en hacer test que nos aseguraran que se recorrían todos los nodos, pero al final decidimos usar dos variaciones del mismo algoritmo. Esto nos va a ayudar a demostrar que el algoritmo que nosotros elejimos en el peor caso tiene una complejidad igual al que realmente nos va a probar la cota N² y en el mejor caso tiene una complejidad lineal.
\\
Con este objetivo a lo largo de los tests modificamos los grafos para observar su comportamiento y poder sacar conclusiones sobre las elecciones algoritmicas que tomamos. En cada test los valores se logran al promediar un tres mil iteraciones sobre el mismo input, sobre que forma tiene el input se va a hablar más adelante.
\\
Tambien vale aclarar que no tenemos muchas restricciones sobre los parámetros del input, esto quiere decir que nada asegura que del input no podamos obtener un pseudo-digrafo. La lectura de datos selecciona las aristas de menor peso y las deja en una matriz. Entonces la creación de la matriz no se toma en cuenta en la ejecución de cada experimento ya que no tenemos que tomar mediciones que incluyan lectura de archivos.
\\Cada instancia de los experimentos fue iteradada 3000 veces, y se calculó el promedio.
\subsubsection{Resultados y análisis}

En nuestro primer experimento corrimos el algoritmo con diferentes grafos Kn, donde el n empieza en 10, se incrementa de a 10 y termina en 250 y los pesos de los ejes se generan de forma aleatoria. Creamos estos parámetros para tener una primera impresión de como variaba, dependiendo solamente de los nodos, ya que los ejes dependen de la cantidad de nodos. Nuestra expectativa era que A1 tenga un comportamiento cuadrático y que A2 tenga un comportamiento errático, pero parecido a una función cuadrática, ya que no sabíamos como iban a afectar la interrupciones que introducimos en el algoritmo, esperábamos mejoras en algunas iteraciones.

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{KnC100r3000}
\caption{}
\end{figure}

Como se puede ver en el gráfico, nuestras expectativas fueron cumplidas, A1 tiene un tendencia cuadrática y A2, aunque no muestra una tendencia clara, está por debajo de A1. Como explicamos anteriormente este comportamiento errático responde a que A2 termina cuando encuentra el camino mínimo para n y no sigue ejecutando para otros nodos, esto quiere decir que cuanto más cerca esta A1 de A2  el camino mínimo de n es uno de los últimos en computarse y análogamente si están lejos es que n es uno de los primeros en computarse.
\\
Al encontar respaldo empírico sobre como nuestro algoritmo cumple con las complejidades teóricas, decidimos evaluar como respondía A1 y A2 sobre el mejor caso, este sería que el camino mínimo sea el eje que va desde 1 hasta n, ya que A2 corta en cuanto encuentra la solución para n. Nuestra complejidad, despues de leer el input es lineal. Lo que creamos es un test que nos crea grafos Kn y que tienen la particularidad de que el eje (1,n) pesa cero, haciendolo el camino mínimo. Debajo se encuentran dos gráficos que modelan este test.

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{KnOptC150r3000}
\caption{}
\end{figure}
\\
En este gráfico podemos ver como A1 mantiene su apariencia cuadratica, pero nos hace pensar que A2 tiene una forma constante, lo cual no nos resulto coherente por lo que sabemos de la implementación, la busqueda lineal del mínimo tiene que seguir ocurriendo. Por eso decidimos mirar solo la línea de A2 para ver que a que función se asemejaba.


\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{KnsoloOptC100r3000}
\caption{}
\end{figure}
\\
Como Podemos observar la apariencia constante de A2 era meramente una apariencia por las escalas que tenía la figura 10. Ahora se nota claramente que A2 en el mejor caso es lineal.
\\
Al finalizar estos experimentos, nos dimos cuenta que modificar la cantidad de nodos y que la cantidad de ejes está en función a la cantidad de nodos nos reducía el univierso de posibles grafos y probablemente habían dependencias en términos de complejidad que nosotros no cubríamos.
\\
 Entonces creamos este experimento, que crea grafos conexos con 200 ejes y varía los nodos desde 20 hasta 199 y los pesos están asignados aleatoriamente. Esperábamos un gráfico muy parecido a la figura 9.

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{Conexo200ejesC150r3000}
\caption{}
\end{figure}

Aunque se pueden ver unas tendencias cuadráticas en el gráfico, y que está por debajo de la cota dada, también podemos ver que la figura 9 tiene los datos de A1 más regulares que en la figura 2. Nuestras hipótesis es que, cuanto más denso es el grafo, más regular quedan las mediciones y cuanto menos denso las mediciones tienden a ser irregulares. Entonces decidimos experimentar sobre grafos menos densos y ver como quedaban las mediciones.
\\
A fin de lo antes mencionado creamos una prueba, que dada una cierta cantidad de nodos, nos generaba cuatro grafos. Definimos el concepto D, como una símil densidad, donde la densidad está definida como la cantidad de ejes en un grafo dado, cuanto más denso el grafo más ejes tiene. D funciona sólo para grafos conexos, 0 es un árbol y 100 es el Kn.

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{VariasDensidades}
\caption{}
\end{figure}

Como se puede observar en el gráfico no se respalda nuestra hipótesis, y nos genera una incertidumbre aún mayor, al encontrar la línea de Arboles muy por encima de las otras tres, que no era la idea intuitiva que nosotros teníamos, donde los grafos menos densos iban a estar acotados por grafos más densos. Aun así el próximo gráfico sin los arboles avala esta idea, y podríamos pensar que el caso de los arboles es una excepción a la regla.

\begin{figure}[H]
\centering
\includegraphics     [width=0.6\textwidth]{VariasDensidadesSinArbol}
\caption{}
\end{figure}

\\
Luego de demostrar que la complejidad Teórica es respaldada por la experimentación, entramos en una series de pruebas que se generaron por la falta de entendimiento de nuestros gráficos y la busqueda de una hipótesis que satisfaga al lector. Lamentablemente no encontramos una, solo encontramos más preguntas sin resolver, que para no agobiar al lector dejamos como meras incógnitas para encarar en un futuro.¿Por qué los árboles tardan una cantidad significante más de tiempo que un grafo fuertemente conexo?¿Cómo se explica la variación de tiempos cuando la cantidad de ejes es la misma pero los nodos aumentan? Acaso fue que las 3000 iteraciones dieron unas mediciones poco estándares o hay una razón por la cual un grafo con 124 nodos tenga el mismo tiempo de ejecución que uno de 170, cuando estos tendrían que ser muy diferentes.


\\

\\
\\



\end{document}
